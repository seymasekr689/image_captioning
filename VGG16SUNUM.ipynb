{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16480635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    " \n",
    "# bu fonksiyon dizindeki her fotoğrafın özelliklerini çıkartır.\n",
    "def extract_features(directory):\n",
    "    #VGG 16 modelinden nesne olusturuldu\n",
    "    model = VGG16()#onceden egitilmiş model olan imegent in agırılıklarından olusturulmus model cagırılır\n",
    "    # model yeniden yapılandırıldı\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    # vgg 16 mimarı özeti:\n",
    "    print(model.summary())\n",
    "    features = dict()\n",
    "    for name in listdir(directory):\n",
    "        # dosyadan resim adları alındı\n",
    "        filename = directory + '/' + name\n",
    "        #goruntu yuklendi ve boyyutları 224,224,3 olarak düzenlendi\n",
    "        image = load_img(filename, target_size=(224, 224,3))\n",
    "        # Goruntuleri matris dizisine cevrildi.(ön işleme için)\n",
    "        image = img_to_array(image)\n",
    "        #görüntü boyutunu (batch_Size,height,width, channel) 'den (height,width, channel) yani (224,224,3)'ten (1,224,224,3) dönüştürür.\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        # goruntu tahmine hazır hale getirildi\n",
    "        image = preprocess_input(image)\n",
    "        # giriş örnekleri için çıktı tahminleri üretildi\n",
    "        feature = model.predict(image)\n",
    "        # foto id si\n",
    "        image_id = name.split('.')[0]\n",
    "        features[image_id] = feature\n",
    "    return features\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Flickr8k_Dataset'\n",
    "features = extract_features(directory)\n",
    "print('Su kadar özellik çıkarıldı: %d' % len(features))\n",
    "dump(features, open('VGG16.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f744ebf",
   "metadata": {},
   "source": [
    "### METIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5160266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuklendı: 8092 \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def yukle(dosya_ismi):\n",
    "    file = open(dosya_ismi, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "def aciklama_yukle(x):\n",
    "    sozluk = dict()  \n",
    "    for sira in x.split('\\n'):\n",
    "        satir = sira.split()\n",
    "        if len(sira) < 2:\n",
    "            continue\n",
    "        resim_id, resim_aciklama = satir[0], satir[1:]\n",
    "       \n",
    "        resim_id = resim_id.split('.')[0]\n",
    "        \n",
    "        resim_aciklama = ' '.join(resim_aciklama)\n",
    "       \n",
    "        if resim_id not in sozluk:\n",
    "            sozluk[resim_id] = list()\n",
    "    \n",
    "        sozluk[resim_id].append(resim_aciklama)\n",
    "    return sozluk\n",
    "\n",
    "\n",
    "def temizle(aciklamalar):\n",
    "    y = str.maketrans('', '', string.punctuation)#punctuation noktalama isaretleridir.maketrans da noktalama isaretlerini bosluk ile değiştirmeye yarar\n",
    "    for key, value in aciklamalar.items():\n",
    "        uzunluk=len(value)\n",
    "        for i in range(uzunluk):\n",
    "            x = value[i]\n",
    "            x = x.split()\n",
    "            x = [word.lower() for word in x]\n",
    "           # x = [w.translate(y) for w in x]\n",
    "            x = [word for word in x if len(word)>1]\n",
    "            value[i] =  ' '.join(x)\n",
    "            \n",
    "def dosyaya_kaydet(aciklamalar, dosya_adi):\n",
    "    satir = list()\n",
    "    for key, value in aciklamalar.items():\n",
    "        for x in value:\n",
    "            satir.append(key + ' ' + x)\n",
    "    data = '\\n'.join(satir)\n",
    "    file = open(dosya_adi, 'w')\n",
    "    file.write(data)\n",
    "    file.close() \n",
    "    \n",
    "    \n",
    "    \n",
    "dosya_adi= 'Flickr8k.token.txt'\n",
    "#altyazıları yukle\n",
    "x = yukle(dosya_adi)\n",
    "#acıklamaları yukle\n",
    "aciklamalar = aciklama_yukle(x)\n",
    "print('yuklendı: %d ' % len(aciklamalar))\n",
    "# kelimeleri temizle\n",
    "temizle(aciklamalar)\n",
    "# dosyaya kaydet\n",
    "dosyaya_kaydet(aciklamalar,'altyazilar.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0348b480",
   "metadata": {},
   "source": [
    "### DERİN ÖĞRENME MODEL TANIMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a7d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri Seti(Eğitim): 6000\n",
      "Açıklamalar: Eğitim=6000\n",
      "Fotograf(Özellik): eğitim=6000\n",
      "Sözcük Boyutu: 7579\n",
      "Açıklama uzunlugu: 34\n",
      "Veri Seti: Test= 1000\n",
      "Açıklama: Test=1000\n",
      "Fotoğraf: Test=1000\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 4096)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 34, 256)      1940224     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 34, 256)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          1048832     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          525312      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7579)         1947803     dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,527,963\n",
      "Trainable params: 5,527,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/20\n",
      "9576/9576 - 4736s - loss: 4.4978 - val_loss: 4.0384\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.03840, saving model to model-ep001-loss4.498-val_loss4.038.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "9576/9576 - 4656s - loss: 3.8078 - val_loss: 3.8835\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.03840 to 3.88346, saving model to model-ep002-loss3.808-val_loss3.883.h5\n",
      "Epoch 3/20\n",
      "9576/9576 - 4629s - loss: 3.5894 - val_loss: 3.8634\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.88346 to 3.86339, saving model to model-ep003-loss3.589-val_loss3.863.h5\n",
      "Epoch 4/20\n",
      "9576/9576 - 4839s - loss: 3.4777 - val_loss: 3.8575\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.86339 to 3.85746, saving model to model-ep004-loss3.478-val_loss3.857.h5\n",
      "Epoch 5/20\n",
      "9576/9576 - 4680s - loss: 3.4166 - val_loss: 3.8915\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.85746\n",
      "Epoch 6/20\n",
      "9576/9576 - 4572s - loss: 3.3778 - val_loss: 3.9342\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.85746\n",
      "Epoch 7/20\n",
      "9576/9576 - 4592s - loss: 3.3530 - val_loss: 3.9155\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.85746\n",
      "Epoch 8/20\n",
      "9576/9576 - 4585s - loss: 3.3372 - val_loss: 3.9610\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.85746\n",
      "Epoch 9/20\n",
      "9576/9576 - 4586s - loss: 3.3244 - val_loss: 3.9777\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.85746\n",
      "Epoch 10/20\n",
      "9576/9576 - 5527s - loss: 3.3250 - val_loss: 4.0179\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.85746\n",
      "Epoch 11/20\n",
      "9576/9576 - 5757s - loss: 3.3226 - val_loss: 4.0315\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.85746\n",
      "Epoch 12/20\n",
      "9576/9576 - 5720s - loss: 3.3205 - val_loss: 4.0837\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.85746\n",
      "Epoch 13/20\n",
      "9576/9576 - 5751s - loss: 3.3250 - val_loss: 4.0762\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.85746\n",
      "Epoch 14/20\n",
      "9576/9576 - 5938s - loss: 3.3269 - val_loss: 4.0884\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.85746\n",
      "Epoch 15/20\n",
      "9576/9576 - 5843s - loss: 3.3261 - val_loss: 4.0760\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.85746\n",
      "Epoch 16/20\n",
      "9576/9576 - 5764s - loss: 3.3306 - val_loss: 4.0856\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.85746\n",
      "Epoch 17/20\n",
      "9576/9576 - 5606s - loss: 3.3351 - val_loss: 4.1228\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.85746\n",
      "Epoch 18/20\n",
      "9576/9576 - 4574s - loss: 3.3399 - val_loss: 4.1595\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.85746\n",
      "Epoch 19/20\n",
      "9576/9576 - 4603s - loss: 3.3422 - val_loss: 4.1661\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.85746\n",
      "Epoch 20/20\n",
      "9576/9576 - 4576s - loss: 3.3456 - val_loss: 4.1794\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.85746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c61db76a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pickle import load\n",
    "from array import array\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    " \n",
    "def yukle(dosya_ismi):\n",
    "    file = open(dosya_ismi, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "#dataset resim acıklamalrı listesidir .jpg kaldırılmıs hali\n",
    "def yukle_tamami(dosyaadi):\n",
    "    x = yukle(dosyaadi)\n",
    "    liste = list()\n",
    "    for satir in x.split('\\n'):\n",
    "        if len(satir) < 1:\n",
    "            continue\n",
    "        y = satir.split('.')[0]\n",
    "        liste.append(y)\n",
    "    return set(liste)\n",
    " \n",
    "# temizlenmiş açklamalar sözlüğü yükle\n",
    "def temizle(aciklamalar):\n",
    "    y = str.maketrans('', '', string.punctuation)#punctuation noktalama isaretleridir.maketrans da noktalama isaretlerini bosluk ile değiştirmeye yarar\n",
    "    for key, value in aciklamalar.items():\n",
    "        uzunluk=len(value)\n",
    "        for i in range(uzunluk):\n",
    "            x = value[i]\n",
    "            x = x.split()\n",
    "            x = [word.lower() for word in x]\n",
    "            x = [w.translate(y) for w in x]\n",
    "            x = [word for word in x if len(word)>1]\n",
    "            value[i] =  'start'+' '.join(x)+'end'\n",
    "\n",
    "# foto özelliklero yukle\n",
    "def foto_ozellikle_yukle(dosyaadi, veriseti):# filename vgg16 dan cıkartılan özellik, train jpegsiz id\n",
    "    tum_ozellikler = load(open(dosyaadi, 'rb'))\n",
    "    ozellikler = {k: tum_ozellikler[k] for k in veriseti}\n",
    "    return ozellikler\n",
    " \n",
    "def id_al(aciklamalar):\n",
    "    id_llistesi = list()\n",
    "    for key in aciklamalar.keys():\n",
    "        [id_llistesi.append(d) for d in aciklamalar[key]]\n",
    "    return id_llistesi # burada teizleniş açıklama ve id sözcüğünden sadece key(id) alır\n",
    " \n",
    "#temizlenmiş açıklamalar buraya gelir\n",
    "def benersiz_tam_Sayi_olustur(aciklamalar):\n",
    "    satirlar_id = id_al(aciklamalar) #train id\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(satirlar_id)# her train id için benzersiz farklı tam sayı verir\n",
    "    return tokenizer\n",
    "  \n",
    "    \n",
    "    \n",
    "# en fazla kelime ile açıklamanın uzunluğunu hesaplama\n",
    "def en_uzun_kelime(aciklamalar):\n",
    "    satir = id_al(aciklamalar)\n",
    "    return max(len(s.split()) for s in satir)\n",
    " \n",
    "    \n",
    "    \n",
    "# bir görüntü için görüntü dizileri, giriş dizileri ve çıktı sözcükleri oluşturma\n",
    "def dizi_olustur(tokenizer, max_kelime, aciklamalar, fotograf, kelime_boyutu):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for key, value in aciklamalar.items():\n",
    "        for x in value:\n",
    "            # sırayı kodla\n",
    "            s = tokenizer.texts_to_sequences([x])[0]  #sayısal ifadelerle belirtilir\n",
    "            for i in range(1, len(s)):\n",
    "                in_s, out_s = s[:i], s[i]\n",
    "                in_s = pad_sequences([in_s], maxlen=max_kelime)[0] #giriş verilerinin sabit uzunlukta olmasını sağlar\n",
    "                out_s = to_categorical([out_s], num_classes=kelime_boyutu)[0]#sınıf vektörünü kelime_boyutu kadar sınıf matrisine dönüştürür\n",
    "                X1.append(fotograf[key][0])\n",
    "                X2.append(in_s)\n",
    "                y.append(out_s)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    " \n",
    "\n",
    "# altyazı modeli tanımlama\n",
    "def model_olusturma(sozluk_boyutu, max_kelime):\n",
    "    # özellik çıkarıcı model(Kodlayıcı)\n",
    "    inputs1 = Input(shape=(4096,))# model fotonun 4096 ogeden olusan vektor olmasını bekler ve fotografın 256 elemanlı temsilini üretmek için işler\n",
    "    fe1 = Dropout(0.3)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "     #Sequence Model\n",
    "    inputs2 = Input(shape=(max_kelime,))\n",
    "    se1 = Embedding(sozluk_boyutu, 256)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "    # kod çözücü model\n",
    "    decoder1 = add([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(sozluk_boyutu, activation='softmax')(decoder2)\n",
    "    # [resm, sıra] [kelime] olacak sekilde bagla\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    print(model.summary())\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model\n",
    " \n",
    "# eğitim veri setini yükle\n",
    "dosyaadi = 'Flickr_8k.trainImages.txt'\n",
    "egitim = yukle_tamami(dosyaadi)\n",
    "print('Veri Seti(Eğitim): %d' % len(egitim))\n",
    "# acıklamalar\n",
    "egitim_aciklamalari = temizle('altyazilar.txt', egitim)# temizlenmiş açıklamalr sözlüğü\n",
    "print('Açıklamalar: Eğitim=%d' % len(egitim_aciklamalari))\n",
    "# özellikler\n",
    "egitim_ozellikleri = foto_ozellikle_yukle('VGG16.pkl', train) # fotogtaf özzellikleri\n",
    "print('Fotograf(Özellik): eğitim=%d' % len(egitim_ozellikleri))\n",
    "\n",
    "benzersiz_Sayi = benersiz_tam_Sayi_olustur(egitim_aciklamalari) # temizlenmiş açıklamalar\n",
    "sozcuk_boyutu = len(benzersiz_Sayi.word_index) + 1 #faklı kelime\n",
    "print('Sözcük Boyutu: %d' % sozcuk_boyutu)\n",
    "# max dizi uzunlugu belirleme\n",
    "max_kelime = en_uzun_kelime(egitim_aciklamalari) #max acıklama uzunlugu\n",
    "print('Açıklama uzunlugu: %d' % max_kelime)\n",
    "\n",
    "\n",
    "\n",
    "X1train, X2train, ytrain = dizi_olustur(benzersiz_Sayi, max_kelime, egitim_aciklamalari, egitim_ozellikleri, sozcuk_boyutu)\n",
    " \n",
    "\n",
    "dosyaadi = 'Flickr_8k.devImages.txt'\n",
    "test = yukle_tamami(dosyaadi)\n",
    "print('Veri Seti: Test= %d' % len(test))\n",
    "# Acıklamalar\n",
    "test_aciklamalari = temizle('altyazilar.txt', test)\n",
    "print('Açıklama: Test=%d' % len(test_aciklamalari))\n",
    "# Fotoğraf Özellikleri\n",
    "test_ozellikleri = foto_ozellikle_yukle('VGG16.pkl', test)\n",
    "print('Fotoğraf: Test=%d' % len(test_ozellikleri))\n",
    "\n",
    "\n",
    "X1test, X2test, ytest = dizi_olustur(benzersiz_Sayi, max_kelime, test_aciklamalari, test_ozellikleri, sozcuk_boyutu)\n",
    "\n",
    "model = model_olusturma(sozcuk_boyutu, max_kelime)\n",
    "\n",
    "filepath = 'model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model.fit([X1train, X2train], ytrain, epochs=20, verbose=2, callbacks=[checkpoint], validation_data=([X1test, X2test], ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a52fa",
   "metadata": {},
   "source": [
    "### DEGERLENDİRME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb27cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri Seti(Eğitim): 6000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "temizle() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1a1c10601a47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[0megitim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myukle_tamami\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdosyaadi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Veri Seti(Eğitim): %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0megitim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m \u001b[0megitim_aciklamalari\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemizle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'altyazilar.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0megitim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Açıklama(Eğitim:%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0megitim_aciklamalari\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenersiz_tam_Sayi_olustur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0megitim_aciklamalari\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: temizle() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from pickle import load\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def yukle(dosya_ismi):\n",
    "    file = open(dosya_ismi, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "#dataset resim acıklamalrı listesidir .jpg kaldırılmıs hali\n",
    "def yukle_tamami(dosyaadi):\n",
    "    x = yukle(dosyaadi)\n",
    "    liste = list()\n",
    "    for satir in x.split('\\n'):\n",
    "        if len(satir) < 1:\n",
    "            continue\n",
    "        y = satir.split('.')[0]\n",
    "        liste.append(y)\n",
    "    return set(liste)\n",
    " \n",
    "# temizlenmiş açklamalar sözlüğü yükle\n",
    "def temizle(aciklamalar):\n",
    "    y = str.maketrans('', '', string.punctuation)#punctuation noktalama isaretleridir.maketrans da noktalama isaretlerini bosluk ile değiştirmeye yarar\n",
    "    for key, value in aciklamalar.items():\n",
    "        uzunluk=len(value)\n",
    "        for i in range(uzunluk):\n",
    "            x = value[i]\n",
    "            x = x.split()\n",
    "            x = [word.lower() for word in x]\n",
    "            x = [w.translate(y) for w in x]\n",
    "            x = [word for word in x if len(word)>1]\n",
    "            value[i] =  'start'+' '.join(x)+'end'\n",
    "\n",
    "# foto özelliklero yukle\n",
    "def foto_ozellikle_yukle(dosyaadi, veriseti):# filename vgg16 dan cıkartılan özellik, train jpegsiz id\n",
    "    tum_ozellikler = load(open(dosyaadi, 'rb'))\n",
    "    ozellikler = {k: tum_ozellikler[k] for k in veriseti}\n",
    "    return ozellikler\n",
    " \n",
    "def id_al(aciklamalar):\n",
    "    id_llistesi = list()\n",
    "    for key in aciklamalar.keys():\n",
    "        [id_llistesi.append(d) for d in aciklamalar[key]]\n",
    "    return id_llistesi # burada teizleniş açıklama ve id sözcüğünden sadece key(id) alır\n",
    " \n",
    "#temizlenmiş açıklamalar buraya gelir\n",
    "def benersiz_tam_Sayi_olustur(aciklamalar):\n",
    "    satirlar_id = id_al(aciklamalar) #train id\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(satirlar_id)# her train id için benzersiz farklı tam sayı verir\n",
    "    return tokenizer\n",
    "  \n",
    "    \n",
    "    \n",
    "# en fazla kelime ile açıklamanın uzunluğunu hesaplama\n",
    "def en_uzun_kelime(aciklamalar):\n",
    "    satir = id_al(aciklamalar)\n",
    "    return max(len(s.split()) for s in satir)\n",
    " \n",
    "# bir tamsayıyı bir kelimeye eşleştirme\n",
    "def tamsayieslestirme(integer, tokenizer):\n",
    "    for kelime, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return kelime\n",
    "    return None\n",
    " \n",
    "#bir resim için bir açıklama oluşturmak\n",
    "def aciklama_olustur(model, tokenizer, foto, max_uzunluk):\n",
    "    baslangic = 'startseq'\n",
    "    #dizinin tüm uzunluğu boyunca yinelemek\n",
    "    for i in range(max_uzunluk):\n",
    "        # tamsayı kodlama giriş sırası\n",
    "        s = tokenizer.texts_to_sequences([baslangic])[0]\n",
    "        s = pad_sequences([s], maxlen=max_uzunluk)\n",
    "        # sonraki kelimeyi tahmin etme\n",
    "        y = model.predict([foto,s], verbose=0)\n",
    "        # olasılığı tam sayıya çevirmek\n",
    "        y = argmax(y)\n",
    "        # tamsayıyı kelimeye eşleme\n",
    "        kelime = tamsayieslestirme(y, tokenizer)\n",
    "        # kelimeyi eşleyemezsek durdur\n",
    "        if kelime is None:\n",
    "            break\n",
    "        #sonraki kelimeyi oluşturmak için girdi olarak ekle\n",
    "        baslangic += ' ' + kelime\n",
    "        #dizinin sonunu tahmin ederse durdue\n",
    "        if kelime == 'endseq':\n",
    "            break\n",
    "    return baslangic\n",
    " \n",
    "# modelin becerisini değerlendirme(BLEU SCORE)\n",
    "def model_olustur(model, aciklamalar, fotograf, tokenizer, max_uzunluk):\n",
    "    print(\"3\")\n",
    "    gercek, tahmin_edilen = list(), list()\n",
    "    #tüm veri setinin üzerinden geç\n",
    "    for key, value in aciklamalar.items():\n",
    "        # acıklama üret\n",
    "        y = aciklama_olustur(model, tokenizer, fotograf[key], max_uzunluk)\n",
    "        #gercek deger ve tahmini değeri tut\n",
    "        x = [v.split() for v in value]\n",
    "        gercek.append(x)\n",
    "        tahmin_edilen.append(y.split())\n",
    "    # BLEU skoru hesapla\n",
    "    print('BLEU-1: %f' % corpus_bleu(gercek, tahmin_edilen, weights=(1.0, 0, 0, 0)))\n",
    "    print(\"BLEU 1 HESAPLANDI\")\n",
    "    #print('BLEU-2: %f' % corpus_bleu(gercek, tahmin_edilen, weights=(0.5, 0.5, 0, 0)))\n",
    "    #print(\"BLEU 2 HESAPLANDI\")\n",
    "    #print('BLEU-3: %f' % corpus_bleu(gercek, tahmin_edilen, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    #print(\"BLEU 3 HESAPLANDI\")\n",
    "    #print('BLEU-4: %f' % corpus_bleu(gercek, tahmin_edilen, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "    #print(\"BLEU 4 HESAPLANDI\")\n",
    "\n",
    "\n",
    "dosyaadi = 'Flickr_8k.trainImages.txt'\n",
    "egitim = yukle_tamami(dosyaadi)\n",
    "print('Veri Seti(Eğitim): %d' % len(egitim))\n",
    "egitim_aciklamalari = temizle('altyazilar.txt', egitim)\n",
    "print('Açıklama(Eğitim:%d' % len(egitim_aciklamalari))\n",
    "tokenizer = benersiz_tam_Sayi_olustur(egitim_aciklamalari)\n",
    "sozcuk_boyutu = len(tokenizer.word_index) + 1\n",
    "print('Sözcuk Boyutu: %d' % sozcuk_boyutu)\n",
    "\n",
    "max_kelime = en_uzun_kelime(egitim_aciklamalari)\n",
    "print('Açıklama Uzunlugu: %d' % max_kelime)\n",
    " \n",
    "\n",
    "dosyaadi = 'Flickr_8k.testImages.txt'\n",
    "test = yukle_tamami(dosyaadi)\n",
    "print('Veri Seti(Test): %d' % len(test))\n",
    "\n",
    "test_aciklamalari = temizle('altyazilar.txt', test)\n",
    "print('Açıklama(Test):%d' % len(test_aciklamalari))\n",
    "\n",
    "test_ozellikleri = foto_ozellikle_yukle('VGG16.pkl', test)\n",
    "print('Fotograf(Test):%d' % len(test_ozellikleri))\n",
    " \n",
    "\n",
    "filename = 'epoch20_model-ep004-loss3.478-val_loss3.857.h5'\n",
    "model = load_model(filename)\n",
    "print(\"1\")\n",
    "model_olustur(model, test_aciklamalari, test_ozellikleri, tokenizer, max_kelime)\n",
    "print(\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e58d34",
   "metadata": {},
   "source": [
    "### YENI ALTYAZI OLUSTURMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import argmax\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    " \n",
    "def ozellik_cikar(dosyaadi):\n",
    "    model = VGG16()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    image = load_img(dosyaadi, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    return feature\n",
    " \n",
    "# bir tamsayıyı bir kelimeye eşleştirme\n",
    "def tamsayieslestirme(integer, tokenizer):\n",
    "    for kelime, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return kelime\n",
    "    return None\n",
    " \n",
    "#bir resim için bir açıklama oluşturmak\n",
    "def aciklama_olustur(model, tokenizer, foto, max_uzunluk):\n",
    "    baslangic = 'startseq'\n",
    "    #dizinin tüm uzunluğu boyunca yinelemek\n",
    "    for i in range(max_uzunluk):\n",
    "        # tamsayı kodlama giriş sırası\n",
    "        s = tokenizer.texts_to_sequences([baslangic])[0]\n",
    "        s = pad_sequences([s], maxlen=max_uzunluk)\n",
    "        # sonraki kelimeyi tahmin etme\n",
    "        y = model.predict([foto,s], verbose=0)\n",
    "        # olasılığı tam sayıya çevirmek\n",
    "        y = argmax(y)\n",
    "        # tamsayıyı kelimeye eşleme\n",
    "        kelime = tamsayieslestirme(y, tokenizer)\n",
    "        # kelimeyi eşleyemezsek durdur\n",
    "        if kelime is None:\n",
    "            break\n",
    "        #sonraki kelimeyi oluşturmak için girdi olarak ekle\n",
    "        baslangic += ' ' + kelime\n",
    "        #dizinin sonunu tahmin ederse durdue\n",
    "        if kelime == 'endseq':\n",
    "            break\n",
    "    return baslangic\n",
    "\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "# maksimum dizi uzunluğunu önceden tanımlandı\n",
    "max_uzunluk = 34\n",
    "\n",
    "model = load_model('epoch20_model-ep004-loss3.478-val_loss3.857.h5')\n",
    "\n",
    "fotograf = ozellik_cikar('aaa.jpg')\n",
    "# açıklama oluştura\n",
    "aciklama = aciklama_olustur(model, tokenizer, fotograf, max_uzunluk)\n",
    "print(aciklama)\n",
    "#man is surfing in the ocea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
